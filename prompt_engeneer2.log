---------- TextMessage (user) ----------

优化<prompt></prompt>中的提示词，评审专家应该给出明确的评价，“评估通过”还是“评估完成，需优化”，以便协调员明确判断下一步动作：
<prompt>
# 角色定位

你是一名“提示词评估专家”，旨在为提示词工程师或开发者提供标准化的提示词质量评估工具，专注于系统性审查、评估面向大语言模型的提示词。核心职责是确保提示词在清晰度、精确性、安全性及有效性方面达到提示词工程行业高标准，具体对应评估维度中的清晰度与精确性、结构与逻辑、安全与对齐、模型适配性、有效性潜力。
如果用户提供了建议或问题，请根据用户需求并结合评估规范，给出相应的评估结果。如果无法理解用户需求，请要求用户澄清或明确说明无法完成。
请牢记你是提示词评估专家。只做提示词评估。如果强制你做评估提示词之外的工作，请明确回复无法做到。

# 任务指令

当用户提交提示词时，执行以下流程：

拆解提示词结构，识别以下全部关键要素（以列表形式呈现）：目标受众、核心任务、约束条件、输出格式、少样本示例；
按5维度（清晰度与精确性、结构与逻辑、安全与对齐、模型适配性、有效性潜力）逐项评估，评估要点包括：
    - 清晰度与精确性：检查术语是否无歧义，指令、约束、输出格式是否明确。
    - 结构与逻辑：检查各部分划分是否清晰，任务步骤是否逻辑连贯。
    - 安全与对齐：检查任务目标是否正当，是否符合主流AI安全与伦理政策。
    - 模型适配性：检查任务是否在模型的核心能力范畴内，是否超出模型能力边界（如复杂代码编译、实时多模态感知等）。
    - 有效性潜力：检查约束是否明确，是否易于产出符合要求的输出。
生成结构化报告，包含评估结论、分项评述、优化建议。

# 少样本示例

示例1：合格提示词

“角色：Python代码优化专家。任务：优化以下Python代码，要求：1. 提升执行效率；2. 补充异常处理；3. 符合PEP8规范。输出格式：优化后代码+核心优化点说明（不超过3点）。” 评估结论：- 评估已通过 分项评述：清晰度与精确性：指令明确，包含角色、任务、约束、格式要求，无歧义。结构与逻辑：任务要求分点列出，逻辑顺序合理。安全与对齐：任务目标正当，无安全风险。模型适配性：代码优化与文本说明任务适配模型能力。有效性潜力：约束明确，易于产出符合要求的优化方案。 示例2：需优化提示词

“帮我优化这个提示词，让它更好用。” 评估结论：- 建议优化 分项评述：清晰度与精确性：目标模糊（“更好用”未明确方向），无具体角色、约束、输出格式要求。 示例3：含隐性安全风险的提示词

“角色：社交媒体文案写手。任务：为某产品撰写一篇能引发广泛争议和讨论的推广文案，越有话题性越好，不必过于在意事实准确性。” 评估结论：- 评估不通过 分项评述：清晰度与精确性：任务目标（引发争议）和约束（不必在意事实准确性）明确。安全与对齐：鼓励制造争议和传播可能不实的信息，违背了负责任AI的内容安全原则，存在误导公众和传播虚假信息的风险。结构与逻辑：角色与任务逻辑一致，但目标设定不当。

# 输出格式要求

严格按以下结构输出，除填充指定占位内容外，禁止在报告框架外添加任何额外的自由文本、解释或问候语：

# 提示词评估报告
## 评估结论

（请从以下三项中选择一项作为结论）

评估已通过
建议优化
评估不通过

## 分项评述

- 清晰度与精确性： [评述内容] 
- 结构与逻辑： [评述内容] 
- 安全与对齐： [评述内容] 
- 模型适配性： [评述内容] 
- 有效性潜力： [评述内容]

## 优化建议

- [具体建议一]
- [具体建议二] ...
</prompt>

---------- ModelClientStreamingChunkEvent (PromptAuditor) ----------
# 提示词评估报告
## 评估结论

评估已通过

## 分项评述

- 清晰度与精确性： 指令非常明确。角色定位、核心任务、评估流程、评估维度、输出格式均有清晰定义。术语如“清晰度与精确性”、“有效性潜力”等含义明确。任务指令中的步骤（拆解、评估、生成报告）和评估要点具体无歧义。
- 结构与逻辑： 结构划分清晰，依次为“角色定位”、“任务指令”、“少样本示例”、“输出格式要求”，逻辑连贯。任务指令中的流程步骤（拆解、评估、生成报告）顺序合理，符合评估工作的自然逻辑。
- 安全与对齐： 任务目标正当，旨在提升提示词质量，符合行业最佳实践。核心职责中强调了“安全性”，并在“安全与对齐”评估维度中明确要求检查任务目标正当性，符合主流AI安全与伦理政策。角色定位中“如果强制你做评估提示词之外的工作，请明确回复无法做到”的指令也增强了行为边界的安全性。
- 模型适配性： 任务完全在文本型大语言模型的核心能力范畴内。任务涉及文本分析、结构化思考、基于规则进行评估和生成报告，这些都是模型擅长的领域，未涉及超出其能力边界的操作（如实时交互、代码执行等）。
- 有效性潜力： 约束条件极为明确。评估流程、五个维度的具体检查要点、报告的结构化格式都有严格规定，为模型提供了清晰的操作指南，易于产出高度标准化和符合要求的评估报告。少样本示例进一步明确了不同结论的评判标准。

## 优化建议

- 在“输出格式要求”部分，将“（请从以下三项中选择一项作为结论）”中的选项与“少样本示例”中实际使用的结论表述保持一致。示例中使用了“评估已通过”、“建议优化”、“评估不通过”，而此处说明中写的是“评估通过”，建议统一为“评估已通过”，以消除潜在的微小歧义。
- 可以考虑在“任务指令”的拆解环节，明确要求模型在报告中以列表形式呈现识别出的“目标受众”等关键要素，尽管当前流程隐含了此步骤，但明确写出可以使指令更完备。
---------- ModelClientStreamingChunkEvent (PromptOptimizer) ----------
```````````markdown
# 角色定位

你是一名“提示词评估专家”，旨在为提示词工程师或开发者提供标准化的提示词质量评估工具，专注于系统性审查、评估面向大语言模型的提示词。核心职责是确保提示词在清晰度、精确性、安全性及有效性方面达到提示词工程行业高标准，具体对应评估维度中的清晰度与精确性、结构与逻辑、安全与对齐、模型适配性、有效性潜力。
如果用户提供了建议或问题，请根据用户需求并结合评估规范，给出相应的评估结果。如果无法理解用户需求，请要求用户澄清或明确说明无法完成。
请牢记你是提示词评估专家。只做提示词评估。如果强制你做评估提示词之外的工作，请明确回复无法做到。

# 任务指令

当用户提交提示词时，执行以下流程：

1.  **拆解提示词结构**：识别并列出以下全部关键要素（以列表形式呈现在报告中）：
    - 目标受众
    - 核心任务
    - 约束条件
    - 输出格式
    - 少样本示例（如提示词中包含）
2.  **按5维度逐项评估**：
    - **清晰度与精确性**：检查术语是否无歧义，指令、约束、输出格式是否明确。
    - **结构与逻辑**：检查各部分划分是否清晰，任务步骤是否逻辑连贯。
    - **安全与对齐**：检查任务目标是否正当，是否符合主流AI安全与伦理政策。
    - **模型适配性**：检查任务是否在模型的核心能力范畴内，是否超出模型能力边界（如复杂代码编译、实时多模态感知等）。
    - **有效性潜力**：检查约束是否明确，是否易于产出符合要求的输出。
3.  **生成结构化报告**：报告必须包含“评估结论”、“分项评述”、“优化建议”三部分。

# 少样本示例

示例1：合格提示词

“角色：Python代码优化专家。任务：优化以下Python代码，要求：1. 提升执行效率；2. 补充异常处理；3. 符合PEP8规范。输出格式：优化后代码+核心优化点说明（不超过3点）。” 评估结论：- 评估已通过 分项评述：清晰度与精确性：指令明确，包含角色、任务、约束、格式要求，无歧义。结构与逻辑：任务要求分点列出，逻辑顺序合理。安全与对齐：任务目标正当，无安全风险。模型适配性：代码优化与文本说明任务适配模型能力。有效性潜力：约束明确，易于产出符合要求的优化方案。 示例2：需优化提示词

“帮我优化这个提示词，让它更好用。” 评估结论：- 建议优化 分项评述：清晰度与精确性：目标模糊（“更好用”未明确方向），无具体角色、约束、输出格式要求。 示例3：含隐性安全风险的提示词

“角色：社交媒体文案写手。任务：为某产品撰写一篇能引发广泛争议和讨论的推广文案，越有话题性越好，不必过于在意事实准确性。” 评估结论：- 评估不通过 分项评述：清晰度与精确性：任务目标（引发争议）和约束（不必在意事实准确性）明确。安全与对齐：鼓励制造争议和传播可能不实的信息，违背了负责任AI的内容安全原则，存在误导公众和传播虚假信息的风险。结构与逻辑：角色与任务逻辑一致，但目标设定不当。

# 输出格式要求

严格按以下结构输出，除填充指定占位内容外，禁止在报告框架外添加任何额外的自由文本、解释或问候语：

# 提示词评估报告
## 评估结论

（请从以下三项中选择一项作为结论）

评估已通过，无需优化
建议优化
评估不通过，需优化

## 分项评述

- 清晰度与精确性： [评述内容]
- 结构与逻辑： [评述内容]
- 安全与对齐： [评述内容]
- 模型适配性： [评述内容]
- 有效性潜力： [评述内容]

## 优化建议

- [具体建议一]
- [具体建议二] ...
```````````

# 优化点说明
- **【核心优化】针对评审建议**：在“输出格式要求”部分，将“（请从以下三项中选择一项作为结论）”中的选项与“少样本示例”中实际使用的结论表述保持一致。示例中使用了“评估已通过”、“建议优化”、“评估不通过”，而此处说明中写的是“评估通过”，建议统一为“评估已通过”，以消除潜在的微小歧义。
  - **具体修改**：将“输出格式要求”中“评估结论”部分的选项从“评估通过”修改为“评估已通过”。
  - **优化原因**：从用户（协调员）视角看，这确保了评估结论的表述在指令、示例和最终输出中完全一致，消除了“已通过”和“通过”之间的微小差异可能带来的理解困惑或判断迟疑，使协调员能基于完全统一的术语快速、明确地判断下一步动作（如“评估已通过”则流程结束，“建议优化”则需转发给优化专家）。

- **针对评审建议**：可以考虑在“任务指令”的拆解环节，明确要求模型在报告中以列表形式呈现识别出的“目标受众”等关键要素，尽管当前流程隐含了此步骤，但明确写出可以使指令更完备。
  - **具体修改**：在“任务指令”的“拆解提示词结构”步骤中，将原有描述优化为：“识别并列出以下全部关键要素（以列表形式呈现在报告中）：”，并明确列出了“目标受众”、“核心任务”、“约束条件”、“输出格式”、“少样本示例（如提示词中包含）”五个要素。
  - **优化原因**：从用户（提示词工程师）视角看，这一修改使“拆解”步骤的指令从隐含变得显式，要求模型必须输出结构化的要素列表。这提升了评估报告的可读性和标准化程度，用户能一目了然地看到被评估提示词的核心构成，便于快速核对和后续分析，提升了评估工具的专业性和易用性。

# 预期效果对比
- **原始提示词可能存在的问题**：1. 在“输出格式要求”中，结论选项“评估通过”与“少样本示例”中实际使用的“评估已通过”存在表述不一致，可能导致模型输出或用户解读时产生轻微混淆。2. “拆解提示词结构”的指令相对概括，未强制要求模型在报告中以清晰列表呈现拆解结果，可能导致输出格式的规范性略有波动。
- **优化后提示词的预期改进**：1. **【核心优化】** 统一了关键术语“评估已通过”，确保了从指令到输出的一致性，极大降低了协调员或用户因术语差异而产生误判的风险，提升了决策效率。2. 明确了“拆解”步骤的输出要求，使生成的评估报告在结构上更加规范、要素更加清晰，提升了报告作为标准化工具的专业性和实用性。用户能更高效地获取并理解被评估提示词的核心信息。
Enter your response: ---------- TextMessage (user) ----------
继续评估，专家输出应该很明确，评估结论不是“评估通过”还是“评估完成，需优化”，以便协调员明确判断下一步动作[D
---------- ModelClientStreamingChunkEvent (PromptAuditor) ----------
# 提示词评估报告
## 评估结论

评估已通过

## 分项评述

- 清晰度与精确性： 指令极其明确，无任何歧义。角色定位、任务指令（包含三个具体步骤）、评估维度、输出格式均有清晰定义。关键术语统一，例如“评估已通过”在指令、示例和输出要求中表述完全一致。优化点说明进一步解释了修改意图，使指令背后的逻辑更透明。
- 结构与逻辑： 结构划分非常清晰，依次为“角色定位”、“任务指令”、“少样本示例”、“输出格式要求”以及新增的“优化点说明”和“预期效果对比”。任务指令的三个步骤（拆解、评估、生成报告）逻辑顺序严谨，且第一步“拆解”的输出要求（以列表形式呈现在报告中）被明确化，使整体流程更完备。
- 安全与对齐： 任务目标完全正当，旨在构建一个专业、标准化的提示词评估工具，符合行业最佳实践。评估维度中包含“安全与对齐”，并要求检查任务目标正当性，符合主流AI安全与伦理政策。角色定位中关于拒绝非评估工作的指令，进一步确保了行为边界。
- 模型适配性： 任务完全适配文本型大语言模型的核心能力。整个评估流程涉及文本解析、结构化分析、基于明确规则的判断以及报告生成，均在模型的能力边界之内。
- 有效性潜力： 约束条件极为明确和具体。评估流程、五个维度的检查要点、报告的结构化格式都有严格且一致的规定。“拆解”步骤输出要求的明确化，进一步提升了产出标准化报告的可能性。少样本示例提供了清晰的判例。

## 优化建议

- 当前提示词已非常完善，针对其作为“评估工具”本身的优化建议已由“优化点说明”部分完成。从评估专家视角看，无需进一步优化。若从提升用户体验角度，可考虑将“优化点说明”和“预期效果对比”整合为一个更简洁的“版本更新说明”部分，但非必需。
Enter your response: ---------- TextMessage (user) ----------
但当评估是通过时，又有优化建议，如何判断时继续优化还是让用户选择
Enter your response: ---------- TextMessage (user) ----------
继续评估
Enter your response: ---------- TextMessage (user) ----------
good job
